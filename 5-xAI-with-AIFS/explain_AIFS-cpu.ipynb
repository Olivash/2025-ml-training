{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44190f7e",
   "metadata": {},
   "source": [
    "# Introduction: Backward Sensitivities (Adjoint/VJP) in AIFS with Anemoi Inference\n",
    "\n",
    "This notebook demonstrates how to use the Anemoi inference framework to analyze the sensitivity of the Artificial Intelligence Forecasting System (AIFS) to changes in its input values, focusing on backward sensitivitiesâ€”also known as adjoint or vector-Jacobian product (VJP) analysis.\n",
    "\n",
    "**What are backward sensitivities?**\n",
    "Backward sensitivities answer questions like:\n",
    "*\"What would a 1K perturbation in the t2m (2-meter temperature) forecast for day-10 around Reading trace back to in the current atmospheric conditions, up to first order?\"*\n",
    "\n",
    "This analysis computes how a small change in a future forecast (e.g., temperature at a specific location and time) can be traced back to the present atmospheric state. This is crucial for understanding which current features most influence future predictions and for model validation and improvement.\n",
    "\n",
    "**How does the perturbation work?**\n",
    "The perturbation created in this notebook applies a change to all data points within a specified radius around a chosen location. This allows us to study the spatial impact of localized changes and how they propagate backward through the model.\n",
    "\n",
    "**What will you learn?**\n",
    "By visualizing these sensitivities, we gain insight into the regions and variables in the current state that most affect the forecast at the target location and time. We will use the `anemoi.inference.runners.sensitivities.SensitivitiesRunner` to compute sensitivities and explore how different input perturbations influence the forecast results.\n",
    "\n",
    "AIFS leverages machine learning and numerical weather prediction data to provide advanced forecasts. Sensitivity analysis helps us understand how variations in input parameters affect the model's outputs, which is crucial for model validation and improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2338b65",
   "metadata": {},
   "source": [
    "## Step-by-Step Sensitivity Analysis Workflow\n",
    "\n",
    "1. **Import Libraries and Modules**\n",
    "   \n",
    "Load required Python libraries and Anemoi modules for sensitivity analysis and plotting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95ba5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "from typing import Any\n",
    "from ecmwf.opendata import Client as OpendataClient\n",
    "\n",
    "from anemoi.inference.outputs.printer import print_state\n",
    "from perturbantion import Perturbation\n",
    "from sensitivities import SensitivitiesRunner\n",
    "\n",
    "from helpers import load_input_state\n",
    "from helpers import haversine\n",
    "from helpers import compute_sensitivities_statistics\n",
    "from plotting import plot_sensitivities\n",
    "from plotting import plot_summary_sfc\n",
    "from plotting import plot_summary_pl\n",
    "from plotting import plot_cross_section\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['ANEMOI_INFERENCE_NUM_CHUNKS'] = '16'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA is not available. Please check your GPU setup.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6782fd",
   "metadata": {},
   "source": [
    "2. **Set Up Experiment Date and Model Checkpoint**\n",
    "\n",
    "Select the forecast date and specify the model checkpoint to use for inference. We recommend an \"o96\" model (~1 deg) to make sure the model fits into 1 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f4492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = OpendataClient().latest()\n",
    "# import datetime\n",
    "# DATE = datetime.datetime(2025, 8, 29, 6, 0)\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0184f8e6-7384-4e70-a4f5-e034bafda15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint already exists in /home/student/2025-ml-training/5-xAI-with-AIFS/aifs-global-o48-cpu.ckpt\n"
     ]
    }
   ],
   "source": [
    "url = \"https://object-store.os-api.cci1.ecmwf.int/ml-tests/test-data/samples/training-course/inference-aifs-o48-cpu.ckpt\"\n",
    "ckpt_file = \"/home/student/2025-ml-training/5-xAI-with-AIFS/aifs-global-o48-cpu.ckpt\"\n",
    "\n",
    "# Create the output directory \n",
    "Path(ckpt_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the checkpoint\n",
    "if not Path(ckpt_file).exists():\n",
    "    process = subprocess.run(\n",
    "        [\"wget\", url, \"-O\", ckpt_file],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(process.stdout)\n",
    "    print(process.stderr)\n",
    "else:\n",
    "    print(f\"Checkpoint already exists in {ckpt_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b99b8b",
   "metadata": {},
   "source": [
    "3. **Load Initial Atmospheric State**\n",
    "\n",
    "Retrieve the input state for the selected date using helper functions.\n",
    "- Print the loaded state for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ecfb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ˜€ date=2025-10-30T00:00:00 fields=90\n",
      "\n",
      "    10u    shape=(2, 10944) min=-24.8247       max=26.6756       \n",
      "    t_150  shape=(2, 10944) min=199.501        max=232.12        \n",
      "    v_400  shape=(2, 10944) min=-56.5153       max=48.6806       \n",
      "    q_850  shape=(2, 10944) min=3.62166e-08    max=0.0184587     \n",
      "    z_100  shape=(2, 10944) min=145252         max=163649        \n",
      "    z_50   shape=(2, 10944) min=185909         max=203845        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load initial conditions\n",
    "input_state = load_input_state(DATE, resolution=\"O48\")\n",
    "print_state(input_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33915f",
   "metadata": {},
   "source": [
    "4. **Initialize Sensitivity Runner**\n",
    "\n",
    "Create a `SensitivitiesRunner` instance with the chosen checkpoint and device (GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be53d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create runner\n",
    "runner = SensitivitiesRunner(\n",
    "    ckpt_file, \n",
    "    device=\"cpu\",\n",
    "    perturb_normalised_space=True,\n",
    "    return_unnormalised_sensitivities=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45894e6",
   "metadata": {},
   "source": [
    "5. **Define Perturbation**\n",
    "\n",
    "The class `LocalPerturbation` is used here to create a local perturbation, but this class can be extended to implement other types of perturbations as needed for different experiments.\n",
    "- Specify the variable to perturb (e.g., 2-meter temperature), location (latitude, longitude), and radius (km) for the perturbation.\n",
    "- The perturbation will affect all data points within the defined radius.\n",
    "- This perturbation adds 1 in the normalised spaced of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e6e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalPerturbation(Perturbation):\n",
    "    \"\"\"Perturbation class.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        checkpoint: str,\n",
    "        perturbed_variable: str,\n",
    "        perturbation_location: float,\n",
    "        perturbation_radius_km: float = 100.0,\n",
    "        patch_metadata: dict[str, Any] = {},\n",
    "    ) -> None:\n",
    "        super().__init__(checkpoint, patch_metadata=patch_metadata)\n",
    "\n",
    "        assert len(perturbation_location) == 2, \"perturbation_location must be a tuple of (lat, lon)\"\n",
    "        assert perturbation_location[0] >= -90 and perturbation_location[0] <= 90, \"Latitude must be between -90 and 90\"\n",
    "        assert perturbation_location[1] >= 0 and perturbation_location[1] <= 360, \"Longitude must be between 0 and 360\"\n",
    "\n",
    "        self.perturbed_variable = perturbed_variable\n",
    "        self.perturbation_location = torch.tensor(perturbation_location)\n",
    "        self.perturbation_radius_km = perturbation_radius_km\n",
    "\n",
    "    def create(self, *args, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"Get the perturbation data.\"\"\"\n",
    "        var_idx = self.variable_to_output_tensor_index[self.perturbed_variable]\n",
    "        perturbation = torch.zeros(self.output_shape)\n",
    "\n",
    "        # Get index of the closest point\n",
    "        dists = haversine(self.coords, self.perturbation_location)\n",
    "        closest_idx = torch.where(dists < self.perturbation_radius_km)[0]\n",
    "\n",
    "        assert len(closest_idx) > 0, \"No grid points found within the specified perturbation radius.\"\n",
    "\n",
    "        perturbation[..., closest_idx, var_idx] = 1.0\n",
    "        return perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0d70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = LocalPerturbation(\n",
    "    ckpt_file,\n",
    "    perturbed_variable=\"2t\",\n",
    "    perturbation_location=(40, 120), # (lat, lon)\n",
    "    perturbation_radius_km=350.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce3fb6",
   "metadata": {},
   "source": [
    "\n",
    "6. **Run Sensitivity Analysis**\n",
    "\n",
    "Execute the runner to compute backward sensitivities for the given input state and perturbation.\n",
    "- Only a 6-hour lead time is supported in this example.\n",
    "- Print the computed sensitivities for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe5388e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Compute sensitivities\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msensitivities\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperturbation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlead_time\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m6h\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# only 6h supported\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensitivities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstats_df\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_sensitivities_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensitivities\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2025-ml-training/5-xAI-with-AIFS/sensitivities.py:266\u001b[39m, in \u001b[36mSensitivitiesRunner.run\u001b[39m\u001b[34m(self, input_state, perturbation, lead_time, return_numpy)\u001b[39m\n\u001b[32m    263\u001b[39m     input_tensor = \u001b[38;5;28mself\u001b[39m.prepare_input_tensor(input_state)\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prepare_output_state(\n\u001b[32m    267\u001b[39m         \u001b[38;5;28mself\u001b[39m.forecast(lead_time, input_tensor, input_state, perturbation), return_numpy\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.report_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/anemoi/inference/runner.py:458\u001b[39m, in \u001b[36mRunner.prepare_output_state\u001b[39m\u001b[34m(self, output, return_numpy)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_output_state\u001b[39m(\n\u001b[32m    441\u001b[39m     \u001b[38;5;28mself\u001b[39m, output: Generator[State, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m], return_numpy: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    442\u001b[39m ) -> Generator[State, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    443\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Prepare the output state.\u001b[39;00m\n\u001b[32m    444\u001b[39m \n\u001b[32m    445\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    456\u001b[39m \u001b[33;03m        The prepared output state.\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_numpy\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Convert fields to numpy arrays\u001b[39;49;00m\n\u001b[32m    461\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2025-ml-training/5-xAI-with-AIFS/sensitivities.py:194\u001b[39m, in \u001b[36mSensitivitiesRunner.forecast\u001b[39m\u001b[34m(self, lead_time, input_tensor_numpy, input_state, perturbation)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Predict next state of atmosphere\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m    190\u001b[39m     torch.autocast(device_type=torch.device(\u001b[38;5;28mself\u001b[39m.device).type, dtype=\u001b[38;5;28mself\u001b[39m.autocast),\n\u001b[32m    191\u001b[39m     ProfilingLabel(\u001b[33m\"\u001b[39m\u001b[33mPredict step\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.use_profiler),\n\u001b[32m    192\u001b[39m     Timer(title),\n\u001b[32m    193\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturbation\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_perturbation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# Update state\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ProfilingLabel(\u001b[33m\"\u001b[39m\u001b[33mUpdating state (CPU)\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.use_profiler):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2025-ml-training/5-xAI-with-AIFS/sensitivities.py:112\u001b[39m, in \u001b[36mSensitivitiesRunner.predict_step\u001b[39m\u001b[34m(self, model, input_tensor_torch, perturbation, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m     LOG.warning(\u001b[33m\"\u001b[39m\u001b[33mCheckpointing error occurred.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(device_type=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m, dtype=\u001b[38;5;28mself\u001b[39m.autocast):\n\u001b[32m    113\u001b[39m         y_pred, t_dx_output = torch.autograd.functional.vjp(\n\u001b[32m    114\u001b[39m             model_func,\n\u001b[32m    115\u001b[39m             input_tensor_torch,\n\u001b[32m   (...)\u001b[39m\u001b[32m    118\u001b[39m             strict=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    119\u001b[39m         )\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m t_dx_output[\u001b[32m0\u001b[39m, ...]\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "# Compute sensitivities\n",
    "for sensitivities in runner.run(input_state=input_state, perturbation=perturbation, lead_time=\"6h\"): # only 6h supported\n",
    "    print_state(sensitivities)\n",
    "    stats_df = compute_sensitivities_statistics(sensitivities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90122671-b989-45b4-9986-25a0e06a3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary_pl(stats_df, stats=[\"min\", \"max\"], cmaps=dict(min=\"Reds_r\", max=\"Blues\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47532381",
   "metadata": {},
   "source": [
    "7. **Visualize Sensitivities**\n",
    "\n",
    "Plot the sensitivities for the perturbed variable (e.g., \"2t\") to see which regions in the current state most influence the forecast.\n",
    "   - Optionally, plot sensitivities for other variables (e.g., \"z_500\") and restrict the visualization to specific areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91632482",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivities(sensitivities, \"2t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivities(sensitivities, \"z_500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sensitivities(sensitivities, \"z_500\", area=(100, 140, 20, 60))\n",
    "# area=(left, right, bottom, top) = (lon_min, lon_max, lat_min, lat_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cross_section(\"t\", sensitivities, latitude=40.5, xlim=(90, 160))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97514bac-20af-4cb1-96b7-875e478e24b2",
   "metadata": {},
   "source": [
    "### Task 5.1: Plot the sensitivities for another location\n",
    "\n",
    "Change the location to your home town and have a look at how the sensitivities differ on different pressure levels of temperature when perturbing 2t.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058b49c-170d-4390-b3a7-356fab13bf37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5225db7-f389-48c2-9862-fb549a40b612",
   "metadata": {},
   "source": [
    "### Task 5.2: Change the perturbation radius\n",
    "\n",
    "How does this effect the sensitivies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f40f2-cdd9-48e4-a2bf-8c51bf2deeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd5a1d29-de60-482c-9e30-2c5a3d53d684",
   "metadata": {},
   "source": [
    "### Task 5.3: Implement your own Perturbation\n",
    "\n",
    "For this task, you are asked to implement your own perturbation class. Instead of using the provided Perturbation base class directly, you should create a new class that inherits from it and overrides the create() method. Your implementation can generate any kind of perturbation you choose. Be creative and explore different spatial or variable patterns. A few examples:\n",
    "\n",
    "- Specify a variable and perturb all pressure levels.\n",
    "- Apply a perturbation to a latitude/longitude strip around the globe instead of a single grid point.\n",
    "- Perturb the entire field rather than one specific location.\n",
    "\n",
    "The goal is to experiment with how different perturbation structures affect the model behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4e1da-b5b0-4cb1-812d-c5434215a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPerturbation(Perturbation):\n",
    "    \"\"\"Perturbation class.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        checkpoint: str,\n",
    "        *args, \n",
    "        **kwargs,\n",
    "        patch_metadata: dict[str, Any] = {},\n",
    "    ) -> None:\n",
    "        super().__init__(checkpoint, patch_metadata=patch_metadata)\n",
    "\n",
    "        ##Â TODO: Save attributes\n",
    "\n",
    "    def create(self, *args, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"Get the perturbation data.\"\"\"\n",
    "        perturbation = torch.zeros(self.output_shape)\n",
    "\n",
    "        # TODO: Create your own perturbation\n",
    "        return perturbation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
