{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3620b1",
   "metadata": {},
   "source": [
    "# Hands-on: Training the AIFS-ENS with Anemoi\n",
    "\n",
    "In this tutorial we will learn how to train the AIFS-ENS (ensemble) model using the anemoi packages. We'll focus on the CRPS (Continuous Ranked Probability Score) based training approach, which is specifically designed for ensemble weather forecasting.\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand the key differences between deterministic and ensemble CRPS training\n",
    "- Learn how to configure the anemoi training pipeline for ensemble models\n",
    "- Build a minimal training configuration step-by-step\n",
    "- Execute a short training run to verify everything works\n",
    "\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Anemoi docu: CRPS-based training](https://anemoi.readthedocs.io/projects/training/en/latest/user-guide/kcrps-set-up.html)\n",
    "- [Anemoi Documentation](https://anemoi.readthedocs.io/projects/training/en/latest/)\n",
    "- [Lang et al. 2024](http://arxiv.org/abs/2412.15832)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91944edf",
   "metadata": {},
   "source": [
    "## Background: What is CRPS Training?\n",
    "\n",
    "The **Continuous Ranked Probability Score (CRPS)** is a proper scoring rule for evaluating probabilistic forecasts. In the context of ensemble weather forecasting, CRPS training allows us to train models that produce multiple ensemble members, each representing a different possible future state of the atmosphere.\n",
    "\n",
    "<img src=\"_resources/aifs-crps_sketch.png\" alt=\"CRPS Sketch\" width=\"900\">\n",
    "\n",
    "### Why Ensemble Training?\n",
    "\n",
    "- **Uncertainty Quantification**: Each ensemble member represents a different possible future\n",
    "- **Probabilistic Forecasting**: Provides uncertainty estimates alongside predictions\n",
    "- **Better Skill Scores**: Often outperforms deterministic models in terms of skill metrics\n",
    "- **Operational Use**: Essential for weather services that need to communicate forecast uncertainty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38bbd5",
   "metadata": {},
   "source": [
    "## CRPS Training in Anemoi\n",
    "\n",
    "### Key Differences: Deterministic vs CRPS Training\n",
    "\n",
    "The main components of the training pipeline need to be modified when switching from deterministic to ensemble CRPS training:\n",
    "\n",
    "| Component | Deterministic | CRPS |\n",
    "|-----------|---------------|------|\n",
    "| **Forecaster** | `GraphForecaster` | `GraphEnsForecaster` |\n",
    "| **Strategy** | `DDPGroupStrategy` | `DDPEnsGroupStrategy` |\n",
    "| **Training Loss** | `WeightedMSELoss` | `AlmostFairKernelCRPS` |\n",
    "| **Model** | `AnemoiModelEncProcDec` | `AnemoiEnsModelEncProcDec` |\n",
    "| **Datamodule** | `AnemoiDatasetsDataModule` | `AnemoiEnsDatasetsDataModule` |\n",
    "\n",
    "\n",
    "#### The AlmostFairKernelCRPS Loss\n",
    "\n",
    "The training uses the AlmostFairKernelCRPS loss function, which combines the traditional CRPS with a \"fair\" version:\n",
    "\n",
    "$$\\text{afCRPS}_\\alpha := \\alpha\\text{fCRPS} + (1-\\alpha)\\text{CRPS}$$\n",
    "\n",
    "Where $\\alpha$ is a trade-off parameter between the CRPS and the fair CRPS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc72ee",
   "metadata": {},
   "source": [
    "## Building Our Training Config\n",
    "\n",
    "Now we'll examine our training configuration step-by-step, highlighting the key differences from deterministic training. We have a minimal configuration file ready that we'll load and examine section by section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0834480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing the necessary modules\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "# Load our minimal configuration file\n",
    "config_path = Path(\"configs/aifs_ens_minimal.yaml\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2b496",
   "metadata": {},
   "source": [
    "### Step 1: Hardware Configuration\n",
    "\n",
    "The hardware configuration needs to specify the number of GPUs per ensemble, which is crucial for the ensemble training strategy.\n",
    "\n",
    "**Key Points:**\n",
    "- `num_gpus_per_ensemble`: Number of GPUs to use per ensemble (typically 1 for small setups)\n",
    "- `num_gpus_per_model`: Number of GPUs per model instance\n",
    "- Total ensemble members = `ensemble_size_per_device` × `num_gpus_per_ensemble` (we'll set this later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323cd553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware Configuration:\n",
      "==================================================\n",
      "accelerator: auto\n",
      "files:\n",
      "  dataset: aifs-ea-an-oper-0001-mars-o48-2010-2022-6h-v1-toy.zarr\n",
      "num_gpus_per_ensemble: 1\n",
      "num_gpus_per_model: 1\n",
      "paths:\n",
      "  data: /datasets/\n",
      "  output: /home/${oc.env:USER}/anemoi-output/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the hardware configuration section\n",
    "print(\"Hardware Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config['hardware'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957c047",
   "metadata": {},
   "source": [
    "### Step 2: Datamodule Configuration\n",
    "\n",
    "For ensemble training, we need to use the `AnemoiEnsDatasetsDataModule` instead of the regular datamodule. This handles ensemble data loading and can work with either:\n",
    "- Single initial conditions for all ensemble members\n",
    "- Perturbed initial conditions (if available in your dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00612cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datamodule configuration:\n",
      "==================================================\n",
      "_target_: anemoi.training.data.datamodule.AnemoiEnsDatasetsDataModule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Datamodule configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config['datamodule'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8f6d1",
   "metadata": {},
   "source": [
    "### Step 3: Model Configuration\n",
    "\n",
    "Key model changes for CRPS-based training are:\n",
    "\n",
    "1. **Ensemble Model Class**: Uses `AnemoiEnsModelEncProcDec` instead of `AnemoiModelEncProcDec`\n",
    "\n",
    "2. **Noise Injector**: Each ensemble member samples random noise at every time step:\n",
    "   ```yaml\n",
    "   noise_injector:\n",
    "     _target_: anemoi.models.layers.ensemble.NoiseConditioning\n",
    "     noise_std: 1\n",
    "     noise_channels_dim: 4\n",
    "     noise_mlp_hidden_dim: 32\n",
    "     inject_noise: True\n",
    "   ```\n",
    "\n",
    "3. **Conditional Layer Normalization**: The processor uses `ConditionalLayerNorm` instead of regular `LayerNorm` to condition the latent space on the noise:\n",
    "   ```yaml\n",
    "   processor:\n",
    "     layer_kernels:\n",
    "       LayerNorm:\n",
    "         _target_: anemoi.models.layers.normalization.ConditionalLayerNorm\n",
    "         normalized_shape: ${model.num_channels}\n",
    "         condition_shape: ${model.noise_injector.noise_channels_dim}\n",
    "   ```\n",
    "\n",
    "   Unlike standard layer normalization that normalizes features independently, conditional layer normalization allows the normalization to be conditioned on additional information (in this case, noise vectors).\n",
    "    - Each ensemble member gets a unique noise vector at every time step\n",
    "    - This noise is embedded and used to condition the layer normalization in the processor\n",
    "    - The conditioning allows the same model weights to produce different outputs for different ensemble members\n",
    "    - This creates diversity in the ensemble predictions while sharing computational resources\n",
    "\n",
    "\n",
    "This noise injection and conditioning is what allows each ensemble member to produce different predictions while sharing the same model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725f3ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "==============================\n",
      "model:\n",
      "  _target_: anemoi.models.models.AnemoiEnsModelEncProcDec\n",
      "noise_injector:\n",
      "  _target_: anemoi.models.layers.ensemble.NoiseConditioning\n",
      "  inject_noise: true\n",
      "  layer_kernels:\n",
      "    Activation:\n",
      "      _target_: torch.nn.GELU\n",
      "  noise_channels_dim: 4\n",
      "  noise_mlp_hidden_dim: 32\n",
      "  noise_std: 1\n",
      "num_channels: 128\n",
      "processor:\n",
      "  _target_: anemoi.models.layers.processor.GraphTransformerProcessor\n",
      "  cpu_offload: ${model.cpu_offload}\n",
      "  layer_kernels:\n",
      "    Activation:\n",
      "      _target_: torch.nn.GELU\n",
      "    KeyNorm:\n",
      "      _target_: anemoi.models.layers.normalization.AutocastLayerNorm\n",
      "      bias: false\n",
      "    LayerNorm:\n",
      "      _target_: anemoi.models.layers.normalization.ConditionalLayerNorm\n",
      "      autocast: false\n",
      "      condition_shape: ${model.noise_injector.noise_channels_dim}\n",
      "      normalized_shape: ${model.num_channels}\n",
      "      w_one_bias_zero_init: true\n",
      "    Linear:\n",
      "      _target_: torch.nn.Linear\n",
      "    QueryNorm:\n",
      "      _target_: anemoi.models.layers.normalization.AutocastLayerNorm\n",
      "      bias: false\n",
      "  mlp_hidden_ratio: 4\n",
      "  num_chunks: 2\n",
      "  num_heads: 16\n",
      "  num_layers: 16\n",
      "  qk_norm: true\n",
      "  sub_graph_edge_attributes: ${model.attributes.edges}\n",
      "  trainable_size: ${model.trainable_parameters.hidden2hidden}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the model configuration section\n",
    "print(\"Model Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "print(yaml.dump(config['model'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f38c4",
   "metadata": {},
   "source": [
    "### Step 4: Training Configuration\n",
    "\n",
    "Now we configure the training parameters, strategy, and loss function for ensemble training.\n",
    "\n",
    "**Key Training Parameters:**\n",
    "\n",
    "1. **Model Task**: Set to `GraphEnsForecaster` (handled by the `ensemble` training default)\n",
    "2. **Ensemble Size**: `ensemble_size_per_device: 2` means 2 ensemble members per device. Thus, the **Total Ensemble Members** is:\n",
    "    ```\n",
    "   ensemble_size_per_device × num_nodes x num_gpus_per_node / ( num_gpus_per_member x num_gpus_per_mod) = 2 × 1 x 1 / (1 x 1) = 2 members\n",
    "   ```\n",
    "   \n",
    "3. **Strategy**: Uses `DDPEnsGroupStrategy` (handled by the `ensemble` training default)\n",
    "4. **Loss Function**: `AlmostFairKernelCRPS` with `alpha=1.0` (pure fair CRPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61009d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "==============================\n",
      "ensemble_size_per_device: 2\n",
      "lr:\n",
      "  iterations: ${training.max_steps}\n",
      "  min: 3e-7\n",
      "  rate: 1e-3\n",
      "  warmup: 1000\n",
      "max_epochs: null\n",
      "max_steps: 16\n",
      "model_task: anemoi.training.train.tasks.GraphEnsForecaster\n",
      "strategy:\n",
      "  _target_: anemoi.training.distributed.strategy.DDPEnsGroupStrategy\n",
      "  num_gpus_per_ensemble: ${hardware.num_gpus_per_ensemble}\n",
      "  num_gpus_per_model: ${hardware.num_gpus_per_model}\n",
      "  read_group_size: ${dataloader.read_group_size}\n",
      "training_loss:\n",
      "  _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS\n",
      "  alpha: 1.0\n",
      "  ignore_nans: false\n",
      "  scalers:\n",
      "  - pressure_level\n",
      "  - general_variable\n",
      "  - nan_mask_weights\n",
      "  - node_weights\n",
      "validation_metrics:\n",
      "  fkcrps:\n",
      "    _target_: anemoi.training.losses.kcrps.AlmostFairKernelCRPS\n",
      "    alpha: 1.0\n",
      "    ignore_nans: false\n",
      "    scalers:\n",
      "    - node_weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the training configuration section\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "print(yaml.dump(config['training'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c32803",
   "metadata": {},
   "source": [
    "## Training Execution\n",
    "\n",
    "Now that we have our configuration ready, let's execute the training. We'll run a short training session to verify everything works correctly by running,\n",
    "\n",
    "```bash\n",
    "anemoi-training train --config-path . --config-name aifs_ens_minimal_config\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6a7635-a840-40cb-bd77-1b3305136a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting AIFS-ENS training...\n",
      "==================================================\n",
      "2025-10-30 17:39:49 INFO Running anemoi training command with overrides: ['--config-path', '/home/student/ml-training-schloer/6-Anemoi/configs/', '--config-name', 'aifs_ens_minimal.yaml']\n",
      "2025-10-30 17:39:53 INFO Prepending current user directory (/home/student/ml-training-schloer/6-Anemoi) to the search path.\n",
      "2025-10-30 17:39:53 INFO Search path is now: [provider=anemoi-cwd-searchpath-plugin, path=/home/student/ml-training-schloer/6-Anemoi, provider=hydra, path=pkg://hydra.conf, provider=main, path=/home/student/ml-training-schloer/6-Anemoi/configs/]\n",
      "/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/anemoi/training/train/train.py:65: UserWarning: A custom validator is returning a value other than `self`.\n",
      "Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\n",
      "See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\n",
      "  self.config = BaseSchema(**config)\n",
      "[2025-10-30 17:39:53,760][anemoi.training.train.train][INFO] - Config validated.\n",
      "[2025-10-30 17:39:53,760][anemoi.training.train.train][INFO] - Starting from checkpoint: False\n",
      "[2025-10-30 17:39:54,361][anemoi.training.diagnostics.logger][INFO] - Maximum number of params allowed to be logged is: 2000\n",
      "[2025-10-30 17:39:54,362][anemoi.training.diagnostics.mlflow.logger][INFO] - MLflow is logging offline.\n",
      "[2025-10-30 17:39:54,821][pytorch_lightning.loggers.mlflow][WARNING] - Experiment with name student-ens-training not found. Creating it.\n",
      "[2025-10-30 17:39:54,862][anemoi.training.diagnostics.mlflow.logger][INFO] - Logging 1 parameters\n",
      "[2025-10-30 17:39:54,863][anemoi.training.diagnostics.mlflow.logger][INFO] - Terminal Log Path: /home/student/anemoi-output/plots/6c6b744993ea4ab2a44e91cb5812ee58/plots/terminal_log.txt\n",
      "[2025-10-30 17:39:54,883][anemoi.training.diagnostics.mlflow.logger][WARNING] - Failed to init AMD GPU Monitor: `pyrsmi` is not installed, if you are running on an AMD GPU                 and want to log GPU metrics please run `pip install pyrsmi`.\n",
      "2025/10/30 17:39:54 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[2025-10-30 17:39:54,884][anemoi.training.train.train][INFO] - Mlflow Run id: 6c6b744993ea4ab2a44e91cb5812ee58\n",
      "[2025-10-30 17:39:54,885][anemoi.training.train.train][INFO] - Run id: 6c6b744993ea4ab2a44e91cb5812ee58\n",
      "[2025-10-30 17:39:54,885][anemoi.training.train.train][INFO] - Parent run server2server: None\n",
      "[2025-10-30 17:39:54,885][anemoi.training.train.train][INFO] - Fork run server2server: None\n",
      "[2025-10-30 17:39:54,885][anemoi.training.train.train][INFO] - Checkpoints path: /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58\n",
      "[2025-10-30 17:39:54,885][anemoi.training.train.train][INFO] - Plots path: /home/student/anemoi-output/plots/6c6b744993ea4ab2a44e91cb5812ee58\n",
      "[2025-10-30 17:39:54,885][anemoi.training.train.train][INFO] - Dry run: False\n",
      "Exception in thread SystemMetricsMonitor:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/ecmwf-ml/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/ecmwf-ml/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/anemoi/utils/config.py:209: UserWarning: Modifying an instance of DotDict(). This class is intended to be immutable.\n",
      "  warnings.warn(\"Modifying an instance of DotDict(). This class is intended to be immutable.\")\n",
      "  File \"/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/mlflow/system_metrics/system_metrics_monitor.py\", line 120, in monitor\n",
      "    self.collect_metrics()\n",
      "  File \"/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/mlflow/system_metrics/system_metrics_monitor.py\", line 146, in collect_metrics\n",
      "    monitor.collect_metrics()\n",
      "  File \"/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/anemoi/training/diagnostics/mlflow/system_metrics/gpu_monitor.py\", line 62, in collect_metrics\n",
      "    tx_kilobytes = pynvml.nvmlDeviceGetPcieThroughput(handle, pynvml.NVML_PCIE_UTIL_TX_BYTES)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/pynvml.py\", line 4315, in nvmlDeviceGetPcieThroughput\n",
      "    _nvmlCheckReturn(ret)\n",
      "  File \"/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/pynvml.py\", line 1059, in _nvmlCheckReturn\n",
      "    raise NVMLError(ret)\n",
      "pynvml.NVMLError_NotSupported: Not Supported\n",
      "[2025-10-30 17:39:55,308][anemoi.graphs.nodes.builders.from_file][INFO] - Reading the dataset from {'dataset': '/datasets//aifs-ea-an-oper-0001-mars-o48-2010-2022-6h-v1-toy.zarr', 'select': ['z_1000', 'z_500', 'z_700', 'z_300', '2t', 't_850', 'tcw', 'z_250', 'lsm', 'z', 'cp', 'tp', 'cos_latitude', 'cos_longitude', 'sin_latitude', 'sin_longitude', 'cos_julian_day', 'cos_local_time', 'sin_julian_day', 'sin_local_time', 'insolation', 'lsm', 'sdor', 'slor', 'z']}.\n",
      "[2025-10-30 17:39:55,947][anemoi.graphs.edges.builders.cutoff][INFO] - Using CutOff-Edges (with radius = 157.6 km) between data and hidden.\n",
      "[2025-10-30 17:39:57,861][anemoi.graphs.edges.builders.knn][INFO] - Using KNN-Edges (with 3 nearest neighbours) between hidden and data.\n",
      "[2025-10-30 17:39:57,875][anemoi.graphs.create][INFO] - Cleaning graph.\n",
      "[2025-10-30 17:39:57,875][anemoi.graphs.create][INFO] - _grid_reference_distance deleted from graph.\n",
      "[2025-10-30 17:39:57,875][anemoi.graphs.create][INFO] - _dataset deleted from graph.\n",
      "[2025-10-30 17:39:57,875][anemoi.graphs.create][INFO] - _grid_reference_distance deleted from graph.\n",
      "[2025-10-30 17:39:57,875][anemoi.graphs.create][INFO] - _node_ordering deleted from graph.\n",
      "[2025-10-30 17:39:57,875][anemoi.graphs.create][INFO] - _resolutions deleted from graph.\n",
      "[2025-10-30 17:39:57,876][anemoi.graphs.create][INFO] - _nx_graph deleted from graph.\n",
      "[2025-10-30 17:39:57,876][anemoi.graphs.create][WARNING] - No output path specified. The graph will not be saved.\n",
      "[2025-10-30 17:39:57,972][anemoi.training.data.datamodule.singledatamodule][WARNING] - Falling back rollout to: 1\n",
      "[2025-10-30 17:39:57,972][anemoi.training.data.datamodule.singledatamodule][INFO] - Timeincrement set to 1 for data with frequency, 21600, and timestep, 21600\n",
      "[2025-10-30 17:39:57,973][anemoi.training.train.train][INFO] - Number of data variables: 23\n",
      "[2025-10-30 17:39:57,973][anemoi.training.train.train][INFO] - Variables: ['z_1000', 'z_500', 'z_700', 'z_300', '2t', 't_850', 'tcw', 'z_250', 'cp', 'tp', 'cos_latitude', 'cos_longitude', 'sin_latitude', 'sin_longitude', 'cos_julian_day', 'cos_local_time', 'sin_julian_day', 'sin_local_time', 'insolation', 'lsm', 'sdor', 'slor', 'z']\n",
      "[2025-10-30 17:39:57,973][anemoi.training.train.train][INFO] - Total number of prognostic variables: 10\n",
      "[2025-10-30 17:39:57,973][anemoi.training.train.train][INFO] - Total number of auxiliary variables: 13\n",
      "[2025-10-30 17:39:57,973][anemoi.training.train.train][INFO] - Total GPU count / model group size: 1 - NB: the learning rate will be scaled by this factor!\n",
      "[2025-10-30 17:39:57,974][anemoi.training.train.train][INFO] - Effective learning rate: 1.000e-03\n",
      "[2025-10-30 17:39:58,038][anemoi.training.train.train][INFO] - MLFlow logger enabled\n",
      "[2025-10-30 17:39:58,040][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)\n",
      "[2025-10-30 17:39:58,059][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True\n",
      "[2025-10-30 17:39:58,059][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores\n",
      "[2025-10-30 17:39:58,059][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs\n",
      "[2025-10-30 17:39:58,100][lightning_fabric.utilities.seed][INFO] - Seed set to 42000\n",
      "[2025-10-30 17:39:58,101][anemoi.training.train.train][INFO] - Initial seed: Rank 0, initial seed 42000, running with random seed: 42000\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_latitude is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_longitude is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_latitude is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_longitude is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_julian_day is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_local_time is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_julian_day is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_local_time is not normalized.\n",
      "[2025-10-30 17:39:58,786][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: insolation is not normalized.\n",
      "[2025-10-30 17:39:58,787][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: lsm is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_latitude is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_longitude is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_latitude is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_longitude is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_julian_day is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: cos_local_time is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_julian_day is not normalized.\n",
      "[2025-10-30 17:39:58,791][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: sin_local_time is not normalized.\n",
      "[2025-10-30 17:39:58,792][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: insolation is not normalized.\n",
      "[2025-10-30 17:39:58,792][anemoi.models.preprocessing.normalizer][INFO] - Normalizing: lsm is not normalized.\n",
      "/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/anemoi/models/preprocessing/normalizer.py:95: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  _norm_mul[i] = 1 / maximum[i]\n",
      "/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/anemoi/utils/config.py:209: UserWarning: Modifying an instance of DotDict(). This class is intended to be immutable.\n",
      "  warnings.warn(\"Modifying an instance of DotDict(). This class is intended to be immutable.\")\n",
      "[2025-10-30 17:39:58,840][anemoi.models.layers.utils][INFO] - Linear kernel: torch.nn.Linear.\n",
      "[2025-10-30 17:39:58,841][anemoi.models.layers.utils][INFO] - LayerNorm kernel: torch.nn.LayerNorm.\n",
      "[2025-10-30 17:39:58,842][anemoi.models.layers.utils][INFO] - Activation kernel: torch.nn.GELU.\n",
      "[2025-10-30 17:39:58,843][anemoi.models.layers.utils][INFO] - QueryNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,844][anemoi.models.layers.utils][INFO] - KeyNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,854][anemoi.models.layers.utils][INFO] - Linear kernel: torch.nn.Linear.\n",
      "[2025-10-30 17:39:58,855][anemoi.models.layers.utils][INFO] - LayerNorm kernel: anemoi.models.layers.normalization.ConditionalLayerNorm.\n",
      "[2025-10-30 17:39:58,856][anemoi.models.layers.utils][INFO] - Activation kernel: torch.nn.GELU.\n",
      "[2025-10-30 17:39:58,857][anemoi.models.layers.utils][INFO] - QueryNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,857][anemoi.models.layers.utils][INFO] - KeyNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,902][anemoi.models.layers.utils][INFO] - Linear kernel: torch.nn.Linear.\n",
      "[2025-10-30 17:39:58,903][anemoi.models.layers.utils][INFO] - LayerNorm kernel: torch.nn.LayerNorm.\n",
      "[2025-10-30 17:39:58,903][anemoi.models.layers.utils][INFO] - Activation kernel: torch.nn.GELU.\n",
      "[2025-10-30 17:39:58,904][anemoi.models.layers.utils][INFO] - QueryNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,905][anemoi.models.layers.utils][INFO] - KeyNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,919][anemoi.models.layers.utils][INFO] - Linear kernel: torch.nn.Linear.\n",
      "[2025-10-30 17:39:58,919][anemoi.models.layers.utils][INFO] - LayerNorm kernel: torch.nn.LayerNorm.\n",
      "[2025-10-30 17:39:58,920][anemoi.models.layers.utils][INFO] - Activation kernel: torch.nn.GELU.\n",
      "[2025-10-30 17:39:58,921][anemoi.models.layers.utils][INFO] - QueryNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,921][anemoi.models.layers.utils][INFO] - KeyNorm kernel: anemoi.models.layers.normalization.AutocastLayerNorm.\n",
      "[2025-10-30 17:39:58,984][anemoi.training.losses.scalers.variable_level][INFO] - Variable Level Scaling: Applying ReluVariableLevelScaler scaling to pl variables ({'param': ['q', 't', 'u', 'v', 'w', 'z']})\n",
      "[2025-10-30 17:39:58,985][anemoi.training.losses.scalers.variable_level][INFO] - with slope = 0.001 and y-intercept/minimum = 0.2.\n",
      "[2025-10-30 17:39:59,067][anemoi.training.train.tasks.ensforecaster][INFO] - Base (config) learning rate: 1.000000e-03 -- Effective learning rate: 1.000000e-03\n",
      "[2025-10-30 17:39:59,067][anemoi.training.train.tasks.ensforecaster][INFO] - Ensemble size: per device = 2, per ens-group = 2\n",
      "[2025-10-30 17:39:59,067][anemoi.training.train.train][INFO] - The following submodules will NOT be trained: []\n",
      "[2025-10-30 17:39:59,081][lightning_fabric.utilities.distributed][INFO] - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[2025-10-30 17:39:59,093][pytorch_lightning.utilities.rank_zero][INFO] - ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[2025-10-30 17:39:59,792][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[2025-10-30 17:39:59,797][anemoi.training.distributed.strategy][INFO] - Rank 0 model_comm_group_id: 0 model_comm_group: [0] model_comm_group_rank: 0 model_comm_group.size(): 1 reader_group_id: 0 reader_group: [0] reader_group_rank: 0 reader_group_root (global): 0 model_reader_groups: [<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f0ff0b4eaf0>] reader_groups: [[<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f0ff0b4eaf0>]]\n",
      "[2025-10-30 17:39:59,798][anemoi.training.distributed.strategy][INFO] - Rank 0 ens_comm_group_id: 0 ens_comm_group: [0] ens_comm_group_rank: 0 ens_comm_group_size: 1 ens_comm_group.size(): 1 ens_comm_subgroup_id: 0 ens_comm_subgroup: [0] ens_comm_subgroup_rank: 0 ens_comm_subgroup.size(): 1\n",
      "[2025-10-30 17:39:59,845][lightning_fabric.utilities.seed][INFO] - [rank: 0] Seed set to 42000\n",
      "[2025-10-30 17:39:59,851][pytorch_lightning.callbacks.model_summary][INFO] -\n",
      "  | Name                  | Type                      | Params | Mode\n",
      "----------------------------------------------------------------------------\n",
      "0 | model                 | AnemoiModelInterface      | 5.2 M  | train\n",
      "1 | loss                  | AlmostFairKernelCRPS      | 0      | train\n",
      "2 | metrics               | ModuleDict                | 0      | train\n",
      "3 | ensemble_ic_generator | EnsembleInitialConditions | 0      | train\n",
      "----------------------------------------------------------------------------\n",
      "5.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 M     Total params\n",
      "20.698    Total estimated model params size (MB)\n",
      "454       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "[2025-10-30 17:39:59,928][anemoi.training.diagnostics.mlflow.logger][INFO] - Logging 478 parameters\n",
      "\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s][2025-10-30 17:40:00,109][anemoi.training.data.datamodule.singledatamodule][WARNING] - Falling back rollout to: 1\n",
      "[2025-10-30 17:40:00,110][anemoi.training.data.dataset.ensdataset][INFO] - NativeGridDataset.set_group_info(): global_rank 0, model_comm_group_id 0, model_comm_group_rank 0, model_comm_num_groups 1, reader_group_rank 0\n",
      "[2025-10-30 17:40:00,110][anemoi.training.data.dataset.ensdataset][INFO] - NativeGridDataset.set_group_info(): global_rank 0, ens_comm_group_id 0, ens_comm_group_rank 0, ens_comm_num_groups 1, reader_group_rank 0\n",
      "[2025-10-30 17:40:00,177][anemoi.training.data.dataset.singledataset][INFO] - Worker 0 (pid 299437, global_rank 0, model comm group 0)  has low/high range 0 / 182\n",
      "[2025-10-30 17:40:00,179][anemoi.training.data.dataset.singledataset][INFO] - Worker 0 (validation, pid 299437, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,179][anemoi.training.data.dataset.ensdataset][INFO] - Worker 0 (validation, pid 299437, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 42000, sanity rnd 0.438636, sanity rnd ini 0.315034)\n",
      "[2025-10-30 17:40:00,199][anemoi.training.data.dataset.singledataset][INFO] - Worker 1 (pid 299445, global_rank 0, model comm group 0)  has low/high range 182 / 364\n",
      "[2025-10-30 17:40:00,202][anemoi.training.data.dataset.singledataset][INFO] - Worker 1 (validation, pid 299445, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,203][anemoi.training.data.dataset.ensdataset][INFO] - Worker 1 (validation, pid 299445, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41999, sanity rnd 0.438636, sanity rnd ini 0.440540)\n",
      "[2025-10-30 17:40:00,238][anemoi.training.data.dataset.singledataset][INFO] - Worker 2 (pid 299453, global_rank 0, model comm group 0)  has low/high range 364 / 546\n",
      "[2025-10-30 17:40:00,241][anemoi.training.data.dataset.singledataset][INFO] - Worker 2 (validation, pid 299453, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,241][anemoi.training.data.dataset.ensdataset][INFO] - Worker 2 (validation, pid 299453, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41998, sanity rnd 0.438636, sanity rnd ini 0.827373)\n",
      "[2025-10-30 17:40:00,281][anemoi.training.data.dataset.singledataset][INFO] - Worker 3 (pid 299461, global_rank 0, model comm group 0)  has low/high range 546 / 728\n",
      "[2025-10-30 17:40:00,285][anemoi.training.data.dataset.singledataset][INFO] - Worker 3 (validation, pid 299461, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,285][anemoi.training.data.dataset.ensdataset][INFO] - Worker 3 (validation, pid 299461, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41997, sanity rnd 0.438636, sanity rnd ini 0.832534)\n",
      "[2025-10-30 17:40:00,281][anemoi.training.data.dataset.singledataset][INFO] - Worker 4 (pid 299469, global_rank 0, model comm group 0)  has low/high range 728 / 910\n",
      "[2025-10-30 17:40:00,290][anemoi.training.data.dataset.singledataset][INFO] - Worker 4 (validation, pid 299469, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,290][anemoi.training.data.dataset.ensdataset][INFO] - Worker 4 (validation, pid 299469, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41996, sanity rnd 0.438636, sanity rnd ini 0.475911)\n",
      "[2025-10-30 17:40:00,325][anemoi.training.data.dataset.singledataset][INFO] - Worker 5 (pid 299477, global_rank 0, model comm group 0)  has low/high range 910 / 1092\n",
      "[2025-10-30 17:40:00,328][anemoi.training.data.dataset.singledataset][INFO] - Worker 5 (validation, pid 299477, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,328][anemoi.training.data.dataset.ensdataset][INFO] - Worker 5 (validation, pid 299477, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41995, sanity rnd 0.438636, sanity rnd ini 0.277514)\n",
      "[2025-10-30 17:40:00,355][anemoi.training.data.dataset.singledataset][INFO] - Worker 6 (pid 299485, global_rank 0, model comm group 0)  has low/high range 1092 / 1274\n",
      "[2025-10-30 17:40:00,358][anemoi.training.data.dataset.singledataset][INFO] - Worker 6 (validation, pid 299485, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,360][anemoi.training.data.dataset.ensdataset][INFO] - Worker 6 (validation, pid 299485, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41994, sanity rnd 0.438636, sanity rnd ini 0.489458)\n",
      "[2025-10-30 17:40:00,384][anemoi.training.data.dataset.singledataset][INFO] - Worker 7 (pid 299493, global_rank 0, model comm group 0)  has low/high range 1274 / 1456\n",
      "[2025-10-30 17:40:00,388][anemoi.training.data.dataset.singledataset][INFO] - Worker 7 (validation, pid 299493, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:00,388][anemoi.training.data.dataset.ensdataset][INFO] - Worker 7 (validation, pid 299493, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41993, sanity rnd 0.438636, sanity rnd ini 0.578038)\n",
      "[2025-10-30 17:40:00,414][anemoi.models.data_indices.collection][INFO] - The order of the variables in the model matches the order in the data.\n",
      "/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:369: You have overridden `on_after_batch_transfer` in `LightningModule` but have passed in a `LightningDataModule`. It will use the implementation from `LightningModule` instance.\n",
      "\n",
      "Sanity Checking:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:  25%|██▌       | 1/4 [00:00<00:02,  1.17it/s]\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]\n",
      "Sanity Checking DataLoader 0:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]\n",
      "\n",
      "[2025-10-30 17:40:02,830][anemoi.training.data.dataset.ensdataset][INFO] - NativeGridDataset.set_group_info(): global_rank 0, model_comm_group_id 0, model_comm_group_rank 0, model_comm_num_groups 1, reader_group_rank 0\n",
      "[2025-10-30 17:40:02,830][anemoi.training.data.dataset.ensdataset][INFO] - NativeGridDataset.set_group_info(): global_rank 0, ens_comm_group_id 0, ens_comm_group_rank 0, ens_comm_num_groups 1, reader_group_rank 0\n",
      "[2025-10-30 17:40:02,897][anemoi.training.data.dataset.singledataset][INFO] - Worker 0 (pid 299526, global_rank 0, model comm group 0)  has low/high range 0 / 2008\n",
      "[2025-10-30 17:40:02,900][anemoi.training.data.dataset.singledataset][INFO] - Worker 0 (train, pid 299526, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:02,901][anemoi.training.data.dataset.ensdataset][INFO] - Worker 0 (train, pid 299526, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 42000, sanity rnd 0.438636, sanity rnd ini 0.315034)\n",
      "[2025-10-30 17:40:02,947][anemoi.training.data.dataset.singledataset][INFO] - Worker 1 (pid 299534, global_rank 0, model comm group 0)  has low/high range 2008 / 4016\n",
      "[2025-10-30 17:40:02,952][anemoi.training.data.dataset.singledataset][INFO] - Worker 1 (train, pid 299534, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:02,952][anemoi.training.data.dataset.ensdataset][INFO] - Worker 1 (train, pid 299534, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41999, sanity rnd 0.438636, sanity rnd ini 0.440540)\n",
      "[2025-10-30 17:40:02,958][anemoi.training.data.dataset.singledataset][INFO] - Worker 2 (pid 299542, global_rank 0, model comm group 0)  has low/high range 4016 / 6024\n",
      "[2025-10-30 17:40:02,961][anemoi.training.data.dataset.singledataset][INFO] - Worker 2 (train, pid 299542, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:02,962][anemoi.training.data.dataset.ensdataset][INFO] - Worker 2 (train, pid 299542, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41998, sanity rnd 0.438636, sanity rnd ini 0.827373)\n",
      "[2025-10-30 17:40:02,996][anemoi.training.data.dataset.singledataset][INFO] - Worker 3 (pid 299550, global_rank 0, model comm group 0)  has low/high range 6024 / 8032\n",
      "[2025-10-30 17:40:02,999][anemoi.training.data.dataset.singledataset][INFO] - Worker 3 (train, pid 299550, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:02,999][anemoi.training.data.dataset.ensdataset][INFO] - Worker 3 (train, pid 299550, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41997, sanity rnd 0.438636, sanity rnd ini 0.832534)\n",
      "[2025-10-30 17:40:03,015][anemoi.training.data.dataset.singledataset][INFO] - Worker 4 (pid 299558, global_rank 0, model comm group 0)  has low/high range 8032 / 10040\n",
      "[2025-10-30 17:40:03,017][anemoi.training.data.dataset.singledataset][INFO] - Worker 4 (train, pid 299558, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:03,018][anemoi.training.data.dataset.ensdataset][INFO] - Worker 4 (train, pid 299558, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41996, sanity rnd 0.438636, sanity rnd ini 0.475911)\n",
      "[2025-10-30 17:40:03,054][anemoi.training.data.dataset.singledataset][INFO] - Worker 5 (pid 299566, global_rank 0, model comm group 0)  has low/high range 10040 / 12048\n",
      "[2025-10-30 17:40:03,056][anemoi.training.data.dataset.singledataset][INFO] - Worker 5 (train, pid 299566, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:03,057][anemoi.training.data.dataset.ensdataset][INFO] - Worker 5 (train, pid 299566, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41995, sanity rnd 0.438636, sanity rnd ini 0.277514)\n",
      "[2025-10-30 17:40:03,084][anemoi.training.data.dataset.singledataset][INFO] - Worker 6 (pid 299574, global_rank 0, model comm group 0)  has low/high range 12048 / 14056\n",
      "[2025-10-30 17:40:03,086][anemoi.training.data.dataset.singledataset][INFO] - Worker 6 (train, pid 299574, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:03,087][anemoi.training.data.dataset.ensdataset][INFO] - Worker 6 (train, pid 299574, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41994, sanity rnd 0.438636, sanity rnd ini 0.489458)\n",
      "[2025-10-30 17:40:03,137][anemoi.models.data_indices.collection][INFO] - The order of the variables in the model matches the order in the data.\n",
      "\n",
      "Training: |          | 0/? [00:00<?, ?it/s][2025-10-30 17:40:03,149][anemoi.training.data.dataset.singledataset][INFO] - Worker 7 (pid 299582, global_rank 0, model comm group 0)  has low/high range 14056 / 16064\n",
      "[2025-10-30 17:40:03,155][anemoi.training.data.dataset.singledataset][INFO] - Worker 7 (train, pid 299582, glob. rank 0, model comm group 0, group_rank 0, seed group id 0, base_seed 42000, sanity rnd 0.315034)\n",
      "[2025-10-30 17:40:03,155][anemoi.training.data.dataset.ensdataset][INFO] - Worker 7 (train, pid 299582, glob. rank 0, model comm group 0, model comm group rank 0, ens comm group 0, ens comm group rank 0,  seed group id 0, seed 41993, sanity rnd 0.438636, sanity rnd ini 0.578038)\n",
      "/opt/conda/envs/ecmwf-ml/lib/python3.12/site-packages/anemoi/utils/config.py:209: UserWarning: Modifying an instance of DotDict(). This class is intended to be immutable.\n",
      "  warnings.warn(\"Modifying an instance of DotDict(). This class is intended to be immutable.\")\n",
      "\n",
      "Training:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Epoch 0:  25%|██▌       | 1/4 [00:01<00:05,  0.53it/s]\n",
      "Epoch 0:  25%|██▌       | 1/4 [00:01<00:05,  0.53it/s, v_num=ee58, train_afkcrps1.00_step=20.50]\n",
      "Epoch 0:  50%|█████     | 2/4 [00:03<00:03,  0.56it/s, v_num=ee58, train_afkcrps1.00_step=20.50]\n",
      "Epoch 0:  50%|█████     | 2/4 [00:03<00:03,  0.56it/s, v_num=ee58, train_afkcrps1.00_step=20.00]\n",
      "Epoch 0:  75%|███████▌  | 3/4 [00:05<00:01,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=20.00]\n",
      "Epoch 0:  75%|███████▌  | 3/4 [00:05<00:01,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=24.10]\n",
      "Epoch 0: 100%|██████████| 4/4 [00:06<00:00,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=24.10]\n",
      "Epoch 0: 100%|██████████| 4/4 [00:06<00:00,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=22.70][2025-10-30 17:40:10,420][anemoi.models.data_indices.collection][INFO] - The order of the variables in the model matches the order in the data.\n",
      "\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:01,  1.91it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 2/4 [00:01<00:01,  1.91it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 3/4 [00:01<00:00,  1.92it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:02<00:00,  1.92it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 0: 100%|██████████| 4/4 [00:09<00:00,  0.44it/s, v_num=ee58, train_afkcrps1.00_step=22.70, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80][2025-10-30 17:40:12,706][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-anemoi-by_epoch-epoch_000-step_000004.ckpt\n",
      "[2025-10-30 17:40:12,706][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-anemoi-by_epoch-epoch_000-step_000004/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:12,707][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-anemoi-by_epoch-epoch_000-step_000004/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:12,708][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-anemoi-by_epoch-epoch_000-step_000004/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:12,892][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/anemoi-by_epoch-epoch_000-step_000004.ckpt\n",
      "[2025-10-30 17:40:12,892][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:12,893][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:12,893][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:12,993][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-last.ckpt\n",
      "[2025-10-30 17:40:12,993][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-last/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:12,994][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-last/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:12,994][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-last/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:13,113][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/last.ckpt\n",
      "[2025-10-30 17:40:13,113][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:13,114][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:13,114][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "\n",
      "Epoch 0: 100%|██████████| 4/4 [00:09<00:00,  0.41it/s, v_num=ee58, train_afkcrps1.00_step=22.70, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s, v_num=ee58, train_afkcrps1.00_step=22.70, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s, v_num=ee58, train_afkcrps1.00_step=22.70, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1:  25%|██▌       | 1/4 [00:01<00:05,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=22.70, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1:  25%|██▌       | 1/4 [00:01<00:05,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=21.50, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1:  50%|█████     | 2/4 [00:03<00:03,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=21.50, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1:  50%|█████     | 2/4 [00:03<00:03,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=21.90, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1:  75%|███████▌  | 3/4 [00:05<00:01,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=21.90, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1:  75%|███████▌  | 3/4 [00:05<00:01,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=21.40, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1: 100%|██████████| 4/4 [00:06<00:00,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=21.40, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80]\n",
      "Epoch 1: 100%|██████████| 4/4 [00:06<00:00,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=22.90, val_afkcrps1.00_step=21.20, val_afkcrps1.00_epoch=22.80, train_afkcrps1.00_epoch=21.80][2025-10-30 17:40:20,041][anemoi.models.data_indices.collection][INFO] - The order of the variables in the model matches the order in the data.\n",
      "\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:01,  1.90it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 2/4 [00:01<00:01,  1.91it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 3/4 [00:01<00:00,  1.92it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 1: 100%|██████████| 4/4 [00:09<00:00,  0.44it/s, v_num=ee58, train_afkcrps1.00_step=22.90, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=21.80][2025-10-30 17:40:22,257][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-anemoi-by_epoch-epoch_001-step_000008.ckpt\n",
      "[2025-10-30 17:40:22,257][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-anemoi-by_epoch-epoch_001-step_000008/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:22,258][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-anemoi-by_epoch-epoch_001-step_000008/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:22,258][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-anemoi-by_epoch-epoch_001-step_000008/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:22,660][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/anemoi-by_epoch-epoch_001-step_000008.ckpt\n",
      "[2025-10-30 17:40:22,660][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:22,662][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:22,662][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:22,855][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-last.ckpt\n",
      "[2025-10-30 17:40:22,855][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-last/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:22,856][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-last/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:22,857][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-last/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:23,166][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/last.ckpt\n",
      "[2025-10-30 17:40:23,166][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:23,167][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:23,167][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "\n",
      "Epoch 1: 100%|██████████| 4/4 [00:10<00:00,  0.40it/s, v_num=ee58, train_afkcrps1.00_step=22.90, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s, v_num=ee58, train_afkcrps1.00_step=22.90, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s, v_num=ee58, train_afkcrps1.00_step=22.90, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2:  25%|██▌       | 1/4 [00:01<00:05,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=22.90, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2:  25%|██▌       | 1/4 [00:01<00:05,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=20.40, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2:  50%|█████     | 2/4 [00:03<00:03,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=20.40, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2:  50%|█████     | 2/4 [00:03<00:03,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=17.30, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2:  75%|███████▌  | 3/4 [00:05<00:01,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=17.30, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2:  75%|███████▌  | 3/4 [00:05<00:01,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=17.60, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2: 100%|██████████| 4/4 [00:06<00:00,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=17.60, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00]\n",
      "Epoch 2: 100%|██████████| 4/4 [00:06<00:00,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=16.70, val_afkcrps1.00_step=18.90, val_afkcrps1.00_epoch=20.30, train_afkcrps1.00_epoch=22.00][2025-10-30 17:40:30,085][anemoi.models.data_indices.collection][INFO] - The order of the variables in the model matches the order in the data.\n",
      "\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:01,  1.94it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 2/4 [00:01<00:01,  1.94it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 3/4 [00:01<00:00,  1.94it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 2: 100%|██████████| 4/4 [00:09<00:00,  0.44it/s, v_num=ee58, train_afkcrps1.00_step=16.70, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=22.00][2025-10-30 17:40:32,315][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-anemoi-by_epoch-epoch_002-step_000012.ckpt\n",
      "[2025-10-30 17:40:32,315][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-anemoi-by_epoch-epoch_002-step_000012/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:32,316][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-anemoi-by_epoch-epoch_002-step_000012/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:32,316][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-anemoi-by_epoch-epoch_002-step_000012/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:32,748][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/anemoi-by_epoch-epoch_002-step_000012.ckpt\n",
      "[2025-10-30 17:40:32,748][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:32,749][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:32,749][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:32,885][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-last.ckpt\n",
      "[2025-10-30 17:40:32,885][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-last/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:32,886][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-last/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:32,886][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-last/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:33,188][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/last.ckpt\n",
      "[2025-10-30 17:40:33,188][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:33,190][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:33,190][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "\n",
      "Epoch 2: 100%|██████████| 4/4 [00:10<00:00,  0.40it/s, v_num=ee58, train_afkcrps1.00_step=16.70, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 2:   0%|          | 0/4 [00:00<?, ?it/s, v_num=ee58, train_afkcrps1.00_step=16.70, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3:   0%|          | 0/4 [00:00<?, ?it/s, v_num=ee58, train_afkcrps1.00_step=16.70, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3:  25%|██▌       | 1/4 [00:01<00:05,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=16.70, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3:  25%|██▌       | 1/4 [00:01<00:05,  0.57it/s, v_num=ee58, train_afkcrps1.00_step=17.20, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3:  50%|█████     | 2/4 [00:03<00:03,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=17.20, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3:  50%|█████     | 2/4 [00:03<00:03,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=15.50, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3:  75%|███████▌  | 3/4 [00:05<00:01,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=15.50, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3:  75%|███████▌  | 3/4 [00:05<00:01,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=15.40, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:06<00:00,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=15.40, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:06<00:00,  0.58it/s, v_num=ee58, train_afkcrps1.00_step=13.80, val_afkcrps1.00_step=15.40, val_afkcrps1.00_epoch=16.10, train_afkcrps1.00_epoch=18.00][2025-10-30 17:40:40,108][anemoi.models.data_indices.collection][INFO] - The order of the variables in the model matches the order in the data.\n",
      "\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 1/4 [00:00<00:01,  1.94it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 2/4 [00:01<00:01,  1.94it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 3/4 [00:01<00:00,  1.95it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\u001b[A\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 3: 100%|██████████| 4/4 [00:09<00:00,  0.44it/s, v_num=ee58, train_afkcrps1.00_step=13.80, val_afkcrps1.00_step=13.60, val_afkcrps1.00_epoch=13.00, train_afkcrps1.00_epoch=18.00][2025-10-30 17:40:42,329][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-anemoi-by_epoch-epoch_003-step_000016.ckpt\n",
      "[2025-10-30 17:40:42,330][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-anemoi-by_epoch-epoch_003-step_000016/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:42,331][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-anemoi-by_epoch-epoch_003-step_000016/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:42,331][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-anemoi-by_epoch-epoch_003-step_000016/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:42,740][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/anemoi-by_epoch-epoch_003-step_000016.ckpt\n",
      "[2025-10-30 17:40:42,740][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:42,741][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:42,741][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:43,384][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/inference-last.ckpt\n",
      "[2025-10-30 17:40:43,384][anemoi.utils.checkpoints][INFO] - Saving metadata to inference-last/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:43,385][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to inference-last/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:43,386][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to inference-last/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:43,864][anemoi.utils.checkpoints][INFO] - Adding extra information to checkpoint /home/student/anemoi-output/checkpoint/6c6b744993ea4ab2a44e91cb5812ee58/last.ckpt\n",
      "[2025-10-30 17:40:43,864][anemoi.utils.checkpoints][INFO] - Saving metadata to archive/anemoi-metadata/ai-models.json\n",
      "[2025-10-30 17:40:43,865][anemoi.utils.checkpoints][INFO] - Saving supporting array `latitudes` to archive/anemoi-metadata/latitudes.numpy (shape=(10944,), dtype=float64)\n",
      "[2025-10-30 17:40:43,865][anemoi.utils.checkpoints][INFO] - Saving supporting array `longitudes` to archive/anemoi-metadata/longitudes.numpy (shape=(10944,), dtype=float64)\n",
      "\n",
      "Epoch 3: 100%|██████████| 4/4 [00:10<00:00,  0.37it/s, v_num=ee58, train_afkcrps1.00_step=13.80, val_afkcrps1.00_step=13.60, val_afkcrps1.00_epoch=13.00, train_afkcrps1.00_epoch=15.50][2025-10-30 17:40:43,873][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_steps=16` reached.\n",
      "\n",
      "Epoch 3: 100%|██████████| 4/4 [00:10<00:00,  0.37it/s, v_num=ee58, train_afkcrps1.00_step=13.80, val_afkcrps1.00_step=13.60, val_afkcrps1.00_epoch=13.00, train_afkcrps1.00_epoch=15.50]2025/10/30 17:40:44 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/30 17:40:44 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "\n",
      "[2025-10-30 17:40:44,151][anemoi.training.diagnostics.mlflow.logger][INFO] - Stopping terminal log monitoring and saving buffered terminal outputs. Final status: SUCCESS\n",
      "==================================================\n",
      "✓ Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys, os \n",
    "\n",
    "# Set environment variables\n",
    "os.environ['ANEMOI_BASE_SEED'] = '42'\n",
    "os.environ['POSSIBLE_USER_WARNINGS'] = 'off'\n",
    "os.environ['TORCH_LOGS'] = \"-dynamo,-inductor\"\n",
    "\n",
    "# Execute the training using subprocess\n",
    "print(\"Starting AIFS-ENS training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    [\n",
    "        \"anemoi-training\", \"train\", \n",
    "        \"--config-path\", \"PATH-TO-YOUR-CONFIG-FOLDER\", \n",
    "        \"--config-name\", \"aifs_ens_minimal.yaml\"\n",
    "    ], \n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,  # Merge stderr into stdout\n",
    "    text=True,\n",
    "    bufsize=1,  # Line buffered\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# Stream output\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    if line:\n",
    "        print(line.rstrip())  # Print immediately to Jupyter cell\n",
    "\n",
    "# Wait for completion\n",
    "return_code = process.wait()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "if return_code == 0:\n",
    "    print(\"✓ Training completed successfully!\")\n",
    "else:\n",
    "    print(f\"❌ Training failed with return code {return_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806adfa8",
   "metadata": {},
   "source": [
    "## Monitoring and Results\n",
    "\n",
    "### MLflow logging\n",
    "\n",
    "Several metrics and parameters are logged during training. Here, we use MLflow to log results offline. \n",
    "\n",
    "In the following we use the MLflow API to plot some key metrics during training, such as:\n",
    "\n",
    "- **Training Loss**: The AlmostFairKernelCRPS loss should decrease over time\n",
    "- **Validation Metrics**: Similar to training loss, calculated on validation data\n",
    "\n",
    "*Note:* Typically the logging is done to a server and can be used interactively on a website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d128d4b7-1a66-4cfa-a395-335115186f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 2b6a878c-c8f9-47d0-adb7-5a3a77388b00\n",
      "Logged metrics:\n",
      "==================================================\n",
      "train_afkcrps1.00_epoch\n",
      "val_afkcrps1.00_epoch\n",
      "val_afkcrps1.00_step\n",
      "epoch\n",
      "val_fkcrps_metric/sfc_tp/1\n",
      "val_fkcrps_metric/sfc_tcw/1\n",
      "val_fkcrps_metric/pl_t/1\n",
      "val_fkcrps_metric/all/1\n",
      "val_fkcrps_metric/pl_z/1\n",
      "val_fkcrps_metric/t_850/1\n",
      "val_fkcrps_metric/sfc_2t/1\n",
      "val_fkcrps_metric/z_500/1\n",
      "val_fkcrps_metric/sfc_cp/1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "run_id=\"6c6b744993ea4ab2a44e91cb5812ee58\"\n",
    "\n",
    "# Start mlflow client and load run\n",
    "client = mlflow.tracking.MlflowClient(tracking_uri=f\"file:///home/{os.getenv(\"USER\")}/anemoi-output/logs/mlflow\")\n",
    "run = client.get_run(run_id)\n",
    "\n",
    "print(f\"Run name: {run.info.run_name}\")\n",
    "print(\"Logged metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for k in run.data.metrics.keys():\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc932b5-6934-42f0-afa8-18778a447615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting \n",
    "metric_names = ['train_afkcrps1.00_epoch', 'val_afkcrps1.00_epoch']\n",
    "\n",
    "# Load data into DataFrame\n",
    "data = []\n",
    "for metric in metric_names:\n",
    "    for entry in client.get_metric_history(run_id, metric):\n",
    "        data.append({'metric': metric, 'step': entry.step, 'value': entry.value, 'time': entry.timestamp})\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot all metrics\n",
    "fig, ax = plt.subplots()\n",
    "for metric in df['metric'].unique():\n",
    "    metric_data = df[df['metric'] == metric].sort_values('step')\n",
    "    ax.plot(metric_data['step'], metric_data['value'], '-o', label=metric)\n",
    "ax.legend()\n",
    "ax.set_xlabel('steps')\n",
    "ax.set_ylabel('loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12b7f8",
   "metadata": {},
   "source": [
    "### Task 1: Change the number of ensemble members\n",
    "\n",
    "Adapt the training config and retrain the model with:\n",
    "   - a larger number of ensemble members, e.g. `ensemble_size_per_device=4`\n",
    "   - train the model for longer by increasing the number of iterations (`max_steps`)\n",
    "\n",
    "**Questions**\n",
    "- How does your loss change with the same number of steps? \n",
    "- How much longer does the training take per iteration?\n",
    "- What happens if you choose a large number of ensemble members?\n",
    "\n",
    "***Note***:\n",
    "\n",
    "You do not need to do the training in the notebook. You can run on the console with: \n",
    "```\n",
    "anemoi-training train --config-path PATH-TO-YOUR-CONFIG-FOLDER --config-name aifs_ens_minimal_config\n",
    "```\n",
    "\n",
    "### (Optional) Task 2: Inference of your model\n",
    "\n",
    "Run inference on the model you have trained. For that, go back to the Jupyter notebook `../4-run-AIFS/inference_aifs-ens.ipynb` and import your used checkpoint. \n",
    "\n",
    "***Note:***\n",
    "\n",
    "You need to adapt, \n",
    "1. The resolution of the data for your input fields to O48\n",
    "\n",
    "```\n",
    "GRID_RESOLUTION = \"O48\"\n",
    "PARAM_SFC = [\"2t\", 'z', 'lsm', \"tcw\", \"sdor\", \"slor\"]\n",
    "PARAM_PL = [\"gh\", \"t\"]\n",
    "LEVELS = [1000, 850, 700, 500, 300, 250]\n",
    "```\n",
    "\n",
    "2. Select only the input fields you need, i.e. ['z_1000', 'z_500', 'z_700', 'z_300', '2t', 't_850', 'tcw', 'z_250', 'lsm', 'z', 'sdor', 'slor'] \n",
    "\n",
    "\n",
    "In case you were not able to train the checkpoint. You can download a checkpoint from here:\n",
    "[https://object-store.os-api.cci1.ecmwf.int/ml-tests/test-data/samples/training-course/inference-aifs-ens-o48.ckpt](https://object-store.os-api.cci1.ecmwf.int/ml-tests/test-data/samples/training-course/inference-aifs-ens-o48.ckpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a249b-e4a2-4536-a181-29362bae9d26",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef3fff-8c45-4a73-ab80-c06b4f2af50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
