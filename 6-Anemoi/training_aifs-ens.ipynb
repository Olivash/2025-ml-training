{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3620b1",
   "metadata": {},
   "source": [
    "# Hands-on: Training the AIFS-ENS with Anemoi\n",
    "\n",
    "In this tutorial we will learn how to train the AIFS-ENS (ensemble) model using the anemoi packages. We'll focus on the CRPS (Continuous Ranked Probability Score) based training approach, which is specifically designed for ensemble weather forecasting.\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand the key differences between deterministic and ensemble CRPS training\n",
    "- Learn how to configure the anemoi training pipeline for ensemble models\n",
    "- Build a minimal training configuration step-by-step\n",
    "- Execute a short training run to verify everything works\n",
    "\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Anemoi docu: CRPS-based training](https://anemoi.readthedocs.io/projects/training/en/latest/user-guide/kcrps-set-up.html)\n",
    "- [Anemoi Documentation](https://anemoi.readthedocs.io/projects/training/en/latest/)\n",
    "- [Lang et al. 2024](http://arxiv.org/abs/2412.15832)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91944edf",
   "metadata": {},
   "source": [
    "## Background: What is CRPS Training?\n",
    "\n",
    "The **Continuous Ranked Probability Score (CRPS)** is a proper scoring rule for evaluating probabilistic forecasts. In the context of ensemble weather forecasting, CRPS training allows us to train models that produce multiple ensemble members, each representing a different possible future state of the atmosphere.\n",
    "\n",
    "<img src=\"_resources/aifs-crps_sketch.png\" alt=\"CRPS Sketch\" width=\"900\">\n",
    "\n",
    "### Why Ensemble Training?\n",
    "\n",
    "- **Uncertainty Quantification**: Each ensemble member represents a different possible future\n",
    "- **Probabilistic Forecasting**: Provides uncertainty estimates alongside predictions\n",
    "- **Better Skill Scores**: Often outperforms deterministic models in terms of skill metrics\n",
    "- **Operational Use**: Essential for weather services that need to communicate forecast uncertainty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38bbd5",
   "metadata": {},
   "source": [
    "## CRPS Training in Anemoi\n",
    "\n",
    "### Key Differences: Deterministic vs CRPS Training\n",
    "\n",
    "The main components of the training pipeline need to be modified when switching from deterministic to ensemble CRPS training:\n",
    "\n",
    "| Component | Deterministic | CRPS |\n",
    "|-----------|---------------|------|\n",
    "| **Forecaster** | `GraphForecaster` | `GraphEnsForecaster` |\n",
    "| **Strategy** | `DDPGroupStrategy` | `DDPEnsGroupStrategy` |\n",
    "| **Training Loss** | `WeightedMSELoss` | `AlmostFairKernelCRPS` |\n",
    "| **Model** | `AnemoiModelEncProcDec` | `AnemoiEnsModelEncProcDec` |\n",
    "| **Datamodule** | `AnemoiDatasetsDataModule` | `AnemoiEnsDatasetsDataModule` |\n",
    "\n",
    "\n",
    "#### The AlmostFairKernelCRPS Loss\n",
    "\n",
    "The training uses the AlmostFairKernelCRPS loss function, which combines the traditional CRPS with a \"fair\" version:\n",
    "\n",
    "$$\\text{afCRPS}_\\alpha := \\alpha\\text{fCRPS} + (1-\\alpha)\\text{CRPS}$$\n",
    "\n",
    "Where $\\alpha$ is a trade-off parameter between the CRPS and the fair CRPS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc72ee",
   "metadata": {},
   "source": [
    "## Building Our Training Config\n",
    "\n",
    "Now we'll examine our training configuration step-by-step, highlighting the key differences from deterministic training. We have a minimal configuration file ready that we'll load and examine section by section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0834480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing the necessary modules\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Load our minimal configuration file\n",
    "config_path = Path(\"configs/aifs_ens_minimal.yaml\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2b496",
   "metadata": {},
   "source": [
    "### Step 1: Hardware Configuration\n",
    "\n",
    "The hardware configuration needs to specify the number of GPUs per ensemble, which is crucial for the ensemble training strategy.\n",
    "\n",
    "**Key Points:**\n",
    "- `num_gpus_per_ensemble`: Number of GPUs to use per ensemble (typically 1 for small setups)\n",
    "- `num_gpus_per_model`: Number of GPUs per model instance\n",
    "- Total ensemble members = `ensemble_size_per_device` × `num_gpus_per_ensemble` (we'll set this later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the hardware configuration section\n",
    "print(\"Hardware Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config['hardware'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957c047",
   "metadata": {},
   "source": [
    "### Step 2: Datamodule Configuration\n",
    "\n",
    "For ensemble training, we need to use the `AnemoiEnsDatasetsDataModule` instead of the regular datamodule. This handles ensemble data loading and can work with either:\n",
    "- Single initial conditions for all ensemble members\n",
    "- Perturbed initial conditions (if available in your dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00612cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Datamodule configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config['datamodule'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8f6d1",
   "metadata": {},
   "source": [
    "### Step 3: Model Configuration\n",
    "\n",
    "Key model changes for CRPS-based training are:\n",
    "\n",
    "1. **Ensemble Model Class**: Uses `AnemoiEnsModelEncProcDec` instead of `AnemoiModelEncProcDec`\n",
    "\n",
    "2. **Noise Injector**: Each ensemble member samples random noise at every time step:\n",
    "   ```yaml\n",
    "   noise_injector:\n",
    "     _target_: anemoi.models.layers.ensemble.NoiseConditioning\n",
    "     noise_std: 1\n",
    "     noise_channels_dim: 4\n",
    "     noise_mlp_hidden_dim: 32\n",
    "     inject_noise: True\n",
    "   ```\n",
    "\n",
    "3. **Conditional Layer Normalization**: The processor uses `ConditionalLayerNorm` instead of regular `LayerNorm` to condition the latent space on the noise:\n",
    "   ```yaml\n",
    "   processor:\n",
    "     layer_kernels:\n",
    "       LayerNorm:\n",
    "         _target_: anemoi.models.layers.normalization.ConditionalLayerNorm\n",
    "         normalized_shape: ${model.num_channels}\n",
    "         condition_shape: ${model.noise_injector.noise_channels_dim}\n",
    "   ```\n",
    "\n",
    "   Unlike standard layer normalization that normalizes features independently, conditional layer normalization allows the normalization to be conditioned on additional information (in this case, noise vectors).\n",
    "    - Each ensemble member gets a unique noise vector at every time step\n",
    "    - This noise is embedded and used to condition the layer normalization in the processor\n",
    "    - The conditioning allows the same model weights to produce different outputs for different ensemble members\n",
    "    - This creates diversity in the ensemble predictions while sharing computational resources\n",
    "\n",
    "\n",
    "This noise injection and conditioning is what allows each ensemble member to produce different predictions while sharing the same model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model configuration section\n",
    "print(\"Model Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "print(yaml.dump(config['model'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f38c4",
   "metadata": {},
   "source": [
    "### Step 4: Training Configuration\n",
    "\n",
    "Now we configure the training parameters, strategy, and loss function for ensemble training.\n",
    "\n",
    "**Key Training Parameters:**\n",
    "\n",
    "1. **Model Task**: Set to `GraphEnsForecaster` (handled by the `ensemble` training default)\n",
    "2. **Ensemble Size**: `ensemble_size_per_device: 2` means 2 ensemble members per device\n",
    "3. **Total Ensemble Members**: `ensemble_size_per_device` × `num_gpus_per_ensemble` = 2 × 1 = 2 members\n",
    "4. **Strategy**: Uses `DDPEnsGroupStrategy` (handled by the `ensemble` training default)\n",
    "5. **Loss Function**: `AlmostFairKernelCRPS` with `alpha=1.0` (pure fair CRPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61009d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the training configuration section\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 30)\n",
    "print(yaml.dump(config['training'], default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c32803",
   "metadata": {},
   "source": [
    "## Training Execution\n",
    "\n",
    "Now that we have our configuration ready, let's execute the training. We'll run a short training session to verify everything works correctly by running,\n",
    "\n",
    "```bash\n",
    "anemoi-training train --config-path . --config-name aifs_ens_minimal_config\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Execute the training using subprocess\n",
    "print(\"Starting AIFS-ENS training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run the training command using subprocess\n",
    "result = subprocess.run([\n",
    "    \"anemoi-training\", \"train\", \n",
    "    \"--config-path\", \"/home/ecm1922/Projects/ml-training-course/2025-ml-training/6-Anemoi/configs\", \n",
    "    \"--config-name\", \"aifs_ens_minimal.yaml\"\n",
    "    ], \n",
    "    check=True,  # Raise exception if command fails\n",
    "    capture_output=True,  # Capture output for display\n",
    "    text=True  # Return output as text\n",
    ")\n",
    "print(result.stdout)\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"\\n✓ Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806adfa8",
   "metadata": {},
   "source": [
    "## Monitoring and Results\n",
    "\n",
    "### Key Metrics to Monitor\n",
    "\n",
    "- **Training Loss**: The AlmostFairKernelCRPS loss should decrease over time\n",
    "- **Validation Metrics**: Similar to training loss, calculated on validation data\n",
    "- **Learning Rate**: Should follow the warmup schedule\n",
    "- **Memory Usage**: Monitor GPU memory usage\n",
    "- **Training Speed**: Steps per second\n",
    "\n",
    "### Output Files\n",
    "\n",
    "The training will create several output files:\n",
    "\n",
    "- **Checkpoints**: Model weights saved periodically (`.ckpt` files)\n",
    "- **Logs**: Training logs and metrics\n",
    "- **MLflow Artifacts**: If MLflow is enabled, check the tracking UI\n",
    "- **Plots**: Diagnostic plots (if enabled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12b7f8",
   "metadata": {},
   "source": [
    "### Follow-up Exercises\n",
    "\n",
    "1. **Run the Training**: Uncomment the training code and execute a real training run\n",
    "2. **Experiment with Parameters**: Try different values for:\n",
    "   - `ensemble_size_per_device` (e.g., 4, 8)\n",
    "   - `alpha` parameter in the loss function (e.g., 0.5, 0.8)\n",
    "   - Generating ensemble forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14ab7f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
